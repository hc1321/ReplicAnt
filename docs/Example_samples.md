# replicAnt

"generating annotated images of animals in complex environments with Unreal Engine"

by [Fabian **Plum**](https://twitter.com/fabian_plum),
[René **Bulla**](https://twitter.com/renebulla),
[Hendrik **Beck**](https://twitter.com/Hendrik_Beck),
[Natalie **Imirzian**](https://twitter.com/nimirzy),
and [David **Labonte**](https://twitter.com/EvoBiomech) (2023)

___

![](../images/06_launch_better_together.png)

___

## Example samples

**INFO**: As these images are embedded at full resolution and are largely uncompressed, in some cases image links may
appear broken. However, all images are linked and can be displayed in full when clicked on!

### _Atta vollenweideri_ - multi animal dataset:

The following samples are part of the datasets used to train detection, semantic segmentation, and classifier networks,
as
presented in [***replicAnt* - generating annotated images of animals in complex environments with Unreal
Engine**](https://www.biorxiv.org/content/10.1101/2023.04.20.537685v1)

<table style="padding:10px">
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1OHvbXQZirAnkj_3bILVSG0Q5EaxojxeK" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1lD0omQ8BLo-eLu7_M1AuLLwDZ6TxWM0z" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1YVgrDgahyWLlJ0ZYqEM_dk_jWen9Ecjy" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1o7cZqfvjDlcYABB9wJHzZ2ONPCfZ2tiX" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1VYvOXCHaEHSKbYL4xwzQz6jbX7NSU6bC" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1_CRCO9qYTbA4RwF1UqmwWsoZ8bbgKdoH" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1yEuwJCk0qPWQfbWdWDmDExMDwGMMQxJF" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1X2KfDIcLrJiEhFpv8pXYjDgptAn2O4gl" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1BZqVD8fokAhaXNO2aVTcW2yRVR4ECwcc" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1cJEIdtVtExrik4T1ziiSDVDkoyHPYvjZ" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1e5NBGGSX5IPpuzI4FMJa0phZldDPlcxf" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1bDIMb_Je28BX8ONUwZ8UYzlE1Ug3vBJ-" width = 500px ></td>
  </tr>
</table>

### _Sungaya inexpectata_ - single animal dataset:

The following samples are part of the datasets used to pose estimation networks, as
presented in [***replicAnt* - generating annotated images of animals in complex environments with Unreal
Engine**](https://www.biorxiv.org/content/10.1101/2023.04.20.537685v1). DeepLabCut annotation conventions are displayed
below each sample.

<table style="padding:10px">
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1WEKeCQMyg3dr77bYzc0wyMfX1ANVpjMU" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1pTLOpi3jIPM0WMx9MH6h4tzIIkcCl8_o" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1IR1_DVslj-f2KiNJv6Q4tIiPWtf4Qg_B" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=174AAXkx_voL7Nbivr5Xz6dSIEElLBtcg" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1_e8myztRpVj1ZVk7HUe-wEl0vjZesFRs" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1VR5ej-FlFWew1oH5u3LBOioWrEQLHpJD" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1kbhfHeHn9edfhVaJjGn9bbchrIqqL9sb" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1rXv1Is79vt9_qpjxCShK74oIPsRnDViN" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1yoLLOaRhzKqzVO_uC8aDgypImqLUk0N-" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1Re4wpU5zlgU_R24-Xg_uNEvWk8CHAYSS" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1VwePNNyjGNChEtfy9-wLpCxk_gMCaY3A" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1lUuspt_oMF3q1i7Hc5Wpx561juPi0XKD" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1xLaNd4MXaiBGJBgz0s3qTcypXGNdiQrB" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=14bqfFZHvdkDBU0kNybtIx5NjX_3Ur8H9" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1TNKBlzZTqDN_7Qc3JPLHci5ZpzKjfY_B" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1i-kHUNRQXTj7fJ9lW9G22dAKqc2Hyo-m" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1rbsHBYwa1RMV8RBwFQ2Fhiyxavzp3vwo" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1I-gQUIGNRH7_rkBD9yUYRRplb6VLtOwA" width = 500px ></td>
  </tr>
</table>

### _Leptoglossus zonatus_ - multi animal dataset:

The following samples are part of the datasets used to semantic segmentation networks, as
presented in [***replicAnt* - generating annotated images of animals in complex environments with Unreal
Engine**](https://www.biorxiv.org/content/10.1101/2023.04.20.537685v1). ID maps (with increased contrast for legibility)
are displayed below each sample.

<table style="padding:10px">
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1Xlydv22JO5rDhbylvlavhxNdFxvJK2FO" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1rNrp2SIYwsPt1Sk8amKOZfX9Ht9xjvCR" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=19UOoZUk3XKobYaChXMYTjWGHovYVgVR2" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1wqzuUQsc8DKpk-Xdy9rfcbquXHcnUHz6" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1h40J2CZyHNca4Ja3Yx22eIIB7P6ypOMW" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1RCwPve_DhiPur_7AQwjZr2z73L1OSkXW" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1EXixm31TktGuoIJL4vi-2lZUvYGfwXtR" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1D7gBPRJ3s-hfzHmXSjAcNJNmwq_tf8sn" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1GK9oaKfIiQpHiEtQcPc7DL7PH8IW0lVi" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1tQn-hw_U5rh5y41I2XYOxI2ItJaDpOAo" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1-NbJPz27KTxWrvoWBp68_coP6W1PKPBq" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1czzr5NsrLjomRABsE001ZJT2V0ezwj08" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1b-k14h44ddolwUwPek-GSQjIMI8jaWPl" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1lgXsDoh0tka4j8omlLPXLFe8k6ATd87D" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1wPNI4bEoCGNoG9vwH6FN_XM2rS9fvYO-" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1YhOy0tVEHyVIJgbsGMoTd5X1JmCkUIBR" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1Jry0GhhZkIo_ReT6I3wW-Qs6jCa3zxTo" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1wTKyfQ4qq4UpH6W5dLjr709K6tT9sEQY" width = 500px ></td>
  </tr>
</table>

---

### Example datasets to build and verify parsers:

Two types of example datasets (one for [single animal](../example_data/input-single), one
for [multi animal](../example_data/input-multi) applications) are located in [../exampled_data](../example_data).

Below are the samples associated
with [../example_data/input-multi/input-multi_01](../example_data/input-multi/input-multi_01.JPG):

<table style="padding:10px">
  <tr> 
   <td><img src="../example_data/input-multi/input-multi_01.JPG" width = 300px ></td>
   <td><img src="../example_data/input-multi/input-multi_01_Depth.png" width = 300px ></td>
  </tr>
  <tr> 
   <td>image pass </td>
   <td>depth pass </td>
  </tr>
    <tr> 
   <td><img src="../example_data/input-multi/input-multi_01_ID.png" width = 300px ></td>
   <td><img src="../example_data/input-multi/input-multi_01_NormalWA.png" width = 300px ></td>
  </tr>
  <tr> 
   <td>id pass</td>
   <td>normal pass </td>
  </tr>
</table>

### Official full datasets:

All datasets, both generated and real, additional SI, and the best performing networks are hosted via Zenodo:

* 3D Models https://zenodo.org/record/7849059 **DOI** : 10.5281/zenodo.7849059
* Detection and Tracking Datasets and Trained networks https://zenodo.org/record/7849417 **DOI** :
  10.5281/zenodo.7849417
* Pose-Estimation Datasets and Trained networks https://zenodo.org/record/7849596 **DOI** : 10.5281/zenodo.7849596
* Semantic And Instance Segmentation Datasets and Trained networks https://zenodo.org/record/7849570 **DOI** :
  10.5281/zenodo.7849570

___

> In case you encounter any problems, consult our [troubleshooting guide](troubleshooting.md), or consider raising an
> **issue** on the replicAnt GitHub page.

## License

© Fabian Plum, Rene Bulla, David Labonte 2023
[MIT License](https://choosealicense.com/licenses/mit/)
